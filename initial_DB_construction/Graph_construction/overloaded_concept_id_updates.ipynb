{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing the ID discrepancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Neo4j Config\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# Pinecone setup\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\", \"us-east1-gcp\")\n",
    "PINECONE_INDEX_NAME = \"belief-embeddings\"\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Pinecone & Neo4j Setup (Assume `index` and `driver` are initialized)\n",
    "CHECKPOINT_FILE = \"processed_neo4j_ids.pkl\"\n",
    "BATCH_SIZE = 100  # Process in batches of 100\n",
    "\n",
    "# Load or initialize processed Neo4j node IDs\n",
    "def load_checkpoint():\n",
    "    \"\"\"Load previously processed Neo4j node IDs to resume without duplication.\"\"\"\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        with open(CHECKPOINT_FILE, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    return set()\n",
    "\n",
    "def save_checkpoint(processed_ids):\n",
    "    \"\"\"Save processed Neo4j node IDs.\"\"\"\n",
    "    with open(CHECKPOINT_FILE, \"wb\") as f:\n",
    "        pickle.dump(processed_ids, f)\n",
    "\n",
    "def fetch_unprocessed_overloaded_concepts():\n",
    "    \"\"\"\n",
    "    Fetch Overloaded_Concept nodes from Neo4j that do NOT already have an 'id' field.\n",
    "    Returns a list of {name, neo4j_id}.\n",
    "    \"\"\"\n",
    "    unprocessed_concepts = []\n",
    "    with driver.session() as session:\n",
    "        results = session.run(\n",
    "            \"\"\"\n",
    "            MATCH (oc:Overloaded_Concept)\n",
    "            WHERE oc.id IS NULL\n",
    "            RETURN oc.name AS name, ID(oc) AS neo4j_id\n",
    "            \"\"\"\n",
    "        )\n",
    "        for record in results:\n",
    "            unprocessed_concepts.append({\n",
    "                \"name\": record[\"name\"],\n",
    "                \"neo4j_id\": record[\"neo4j_id\"]\n",
    "            })\n",
    "\n",
    "    return unprocessed_concepts\n",
    "\n",
    "\n",
    "def process_overloaded_concepts():\n",
    "    \"\"\"\n",
    "    Lookup Pinecone IDs and attach them to Overloaded_Concept nodes in Neo4j.\n",
    "    \"\"\"\n",
    "    processed_ids = load_checkpoint()\n",
    "    concepts_to_process = fetch_unprocessed_overloaded_concepts()\n",
    "\n",
    "    # Filter out already processed ones\n",
    "    unprocessed_concepts = [c for c in concepts_to_process if c[\"neo4j_id\"] not in processed_ids]\n",
    "    logger.info(f\"üîé {len(unprocessed_concepts)} Overloaded_Concepts to process.\")\n",
    "\n",
    "    if not unprocessed_concepts:\n",
    "        logger.info(\"‚úÖ No unprocessed concepts found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    for i in range(0, len(unprocessed_concepts), BATCH_SIZE):\n",
    "        batch = unprocessed_concepts[i : i + BATCH_SIZE]\n",
    "        update_queries = []\n",
    "        batch_processed_ids = []\n",
    "\n",
    "        for concept in batch:\n",
    "            concept_name = concept[\"name\"]\n",
    "            neo4j_id = concept[\"neo4j_id\"]\n",
    "\n",
    "\n",
    "            # Get vector dimension\n",
    "            index_stats = index.describe_index_stats()\n",
    "            VECTOR_DIM = index_stats[\"dimension\"]  # Set this dynamically\n",
    "\n",
    "            response = index.query(\n",
    "                vector=[0] * VECTOR_DIM,  # Dummy zero vector of the correct dimension\n",
    "                filter={\"concept\": {\"$eq\": concept_name}},  # Ensure exact match\n",
    "                top_k=1,\n",
    "                include_metadata=True\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            if not response.matches:\n",
    "                logger.warning(f\"‚ö†Ô∏è Pinecone ID missing for '{concept_name}', skipping.\")\n",
    "                continue\n",
    "\n",
    "            pinecone_id = response.matches[0].id  # Get the exact Pinecone vector ID\n",
    "\n",
    "            # Create Cypher query to update the Neo4j node\n",
    "            update_queries.append(\n",
    "                {\"neo4j_id\": neo4j_id, \"pinecone_id\": pinecone_id}\n",
    "            )\n",
    "\n",
    "        # Batch update Neo4j\n",
    "        try:\n",
    "            with driver.session() as session:\n",
    "                session.run(\n",
    "                    \"\"\"\n",
    "                    UNWIND $updates AS update\n",
    "                    MATCH (oc:Overloaded_Concept)\n",
    "                    WHERE ID(oc) = update.neo4j_id\n",
    "                    SET oc.id = update.pinecone_id\n",
    "                    \"\"\",\n",
    "                    updates=update_queries\n",
    "                )\n",
    "\n",
    "            # Save processed IDs only if Neo4j update succeeds\n",
    "            batch_processed_ids = [c[\"neo4j_id\"] for c in update_queries]\n",
    "            processed_ids.update(batch_processed_ids)\n",
    "            save_checkpoint(processed_ids)\n",
    "\n",
    "            logger.info(f\"‚úÖ Updated {len(batch_processed_ids)} Overloaded_Concepts in Neo4j.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Neo4j update failed: {str(e)}\")\n",
    "            logger.error(\"üî¥ Hard stopping due to write failure.\")\n",
    "            return\n",
    "\n",
    "        # Log progress\n",
    "        if (i // BATCH_SIZE) % 1 == 0:  # Log every batch\n",
    "            logger.info(f\"üì¢ Processed {i + BATCH_SIZE}/{len(unprocessed_concepts)} concepts...\")\n",
    "\n",
    "# Run the function\n",
    "process_overloaded_concepts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
