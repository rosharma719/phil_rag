{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since concepts and beliefs were extracted from documents, there are duplicate Concept nodes, but with separate origins and meanings.\n",
    "We're going to restructure the nodes to combine synonymous nodes into a new class apart from Belief and Concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Neo4j Config\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# Script Constants\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "RESET_OVERLOADED_NODES = False\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Logging setup\n",
    "LOG_FILE = \"concept_processing.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "        logging.FileHandler(LOG_FILE)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"‚úÖ Logging initialized.\")\n",
    "\n",
    "# Initialize Neo4j Connection\n",
    "def init_neo4j():\n",
    "    if not NEO4J_URI:\n",
    "        raise ValueError(\"‚ö†Ô∏è NEO4J_URI is not set. Check your .env file.\")\n",
    "    \n",
    "    driver = GraphDatabase.driver(\n",
    "        NEO4J_URI,\n",
    "        auth=(NEO4J_USER, NEO4J_PASSWORD),\n",
    "        max_connection_lifetime=3600\n",
    "    )\n",
    "    with driver.session() as session:\n",
    "        if session.run(\"RETURN 1\").single():\n",
    "            logger.info(\"‚úÖ Successfully connected to Neo4j\")\n",
    "            return driver\n",
    "    raise Exception(\"‚ùå Failed to connect to Neo4J.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_overloaded_nodes(driver):\n",
    "    if RESET_OVERLOADED_NODES:\n",
    "        with driver.session() as session:\n",
    "            result = session.run(\"MATCH (oc:Overloaded_Concept) DETACH DELETE oc RETURN count(*) as deleted\")\n",
    "            deleted = result.single()[\"deleted\"]\n",
    "            logger.info(f\"‚ùå Deleted {deleted} Overloaded_Concept nodes.\")\n",
    "\n",
    "class ProcessTracker:\n",
    "    def __init__(self):\n",
    "        self.processed_ids = set()\n",
    "\n",
    "    def mark_processed(self, vec_ids):\n",
    "        if vec_ids:\n",
    "            self.processed_ids.update(vec_ids)\n",
    "\n",
    "def find_duplicate_concepts(driver):\n",
    "    duplicate_concepts = {}\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\n",
    "            \"\"\"\n",
    "            MATCH (c:Concept)\n",
    "            WITH c.concept as concept_name, collect(c) as concepts\n",
    "            WHERE size(concepts) > 1\n",
    "            RETURN concept_name, [c IN concepts | {\n",
    "                id: c.id, \n",
    "                sep_id: c.sep_id, \n",
    "                document_title: c.document_title\n",
    "            }] as concept_instances\n",
    "            \"\"\"\n",
    "        )\n",
    "        for record in result:\n",
    "            concept_name = record[\"concept_name\"]\n",
    "            instances = record[\"concept_instances\"]\n",
    "            duplicate_concepts[concept_name] = instances\n",
    "    logger.info(f\"üîç Found {len(duplicate_concepts)} concepts with duplicates\")\n",
    "    return duplicate_concepts\n",
    "\n",
    "def merge_duplicate_concepts(driver, duplicate_concepts, tracker):\n",
    "    total_merged = 0\n",
    "    processed_ids = set()\n",
    "    with tqdm(total=len(duplicate_concepts), desc=\"Merging duplicate concepts\") as pbar:\n",
    "        with driver.session() as session:\n",
    "            for concept_name, instances in duplicate_concepts.items():\n",
    "                try:\n",
    "                    ids = [instance[\"id\"] for instance in instances]\n",
    "                    sep_ids = [instance[\"sep_id\"] for instance in instances]\n",
    "                    doc_titles = [instance[\"document_title\"] for instance in instances]\n",
    "                    session.run(\n",
    "                        \"\"\"\n",
    "                        MERGE (oc:Overloaded_Concept {name: $name})\n",
    "                        SET oc.type = \"overloaded_concept\",\n",
    "                            oc.sep_ids = $sep_ids,\n",
    "                            oc.document_titles = $doc_titles,\n",
    "                            oc.vector_ids = $vector_ids\n",
    "                        \"\"\",\n",
    "                        name=concept_name,\n",
    "                        sep_ids=sep_ids,\n",
    "                        doc_titles=doc_titles,\n",
    "                        vector_ids=ids\n",
    "                    )\n",
    "                    delete_result = session.run(\n",
    "                        \"\"\"\n",
    "                        MATCH (c:Concept) \n",
    "                        WHERE c.id IN $ids\n",
    "                        DETACH DELETE c\n",
    "                        RETURN count(*) as deleted\n",
    "                        \"\"\",\n",
    "                        ids=ids\n",
    "                    )\n",
    "                    deleted = delete_result.single()[\"deleted\"]\n",
    "                    logger.info(f\"üîÑ Merged '{concept_name}' from {len(ids)} concepts, deleted {deleted} nodes\")\n",
    "                    processed_ids.update(ids)\n",
    "                    total_merged += 1\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"‚ùå Error processing '{concept_name}': {str(e)}\")\n",
    "                pbar.update(1)\n",
    "    tracker.mark_processed(list(processed_ids))\n",
    "    logger.info(f\"‚úÖ Successfully merged {total_merged} duplicate concepts\")\n",
    "    return total_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    driver = init_neo4j()\n",
    "    reset_overloaded_nodes(driver)\n",
    "    tracker = ProcessTracker()\n",
    "    try:\n",
    "        logger.info(\"üîç Searching for duplicate concepts across the database...\")\n",
    "        duplicate_concepts = find_duplicate_concepts(driver)\n",
    "        if duplicate_concepts:\n",
    "            merge_duplicate_concepts(driver, duplicate_concepts, tracker)\n",
    "        else:\n",
    "            logger.info(\"‚ÑπÔ∏è No duplicate concepts found in the database\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Unexpected error: {str(e)}\")\n",
    "    finally:\n",
    "        driver.close()\n",
    "        logger.info(\"‚úÖ Script execution completed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do the same thing for Pinecone, and attach that to this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
